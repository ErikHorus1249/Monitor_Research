

## 1. Mô hình 

![](https://imgur.com/8If72Nt)


## 2. Khởi tạo môi trường

### 2.1. Cấu hình trên các Host Agent

- Cấu hình các  Agent. Chú ý thay trường IP và zabbix theo môi trường
- Đối với CEPH sẽ cài trên các node mgr, với openstack thì cài đặt trên các node Controller
```
hostname=`hostname`
IP='192.168.30.133'
zabbix="192.168.30.194"
sed -i "s/# SourceIP=*/SourceIP=$IP/" /etc/zabbix/zabbix_agentd.conf
sed -i "s/# ListenIP=.*/ListenIP=$IP/" /etc/zabbix/zabbix_agentd.conf
sed -i "s/# ListenPort=10050/ListenPort=10050/" /etc/zabbix/zabbix_agentd.conf
sed -i "s/Server=127.0.0.1/Server=$zabbix/" /etc/zabbix/zabbix_agentd.conf
sed -i "s/ServerActive=127.0.0.1/ServerActive=$zabbix/" /etc/zabbix/zabbix_agentd.conf
sed -i "s/# SourceIP=*/SourceIP=$IP/" /etc/zabbix/zabbix_agentd.conf
sed -i "s/Hostname=Zabbix server/Hostname=`hostname`/" /etc/zabbix/zabbix_agentd.conf
```

- Khởi động agent zabbix 
```
systemctl enable  zabbix-agent 
systemctl start  zabbix-agent 
systemctl status  zabbix-agent 
```
- Cấu hình firewalld
```
firewall-cmd --add-port=10050/tcp --permanent
firewall-cmd --reload
```

## 2.1. Cấu hình trên các node CEPH


- Cài đặt Zabbix Sender 
```
yum install -y zabbix-sender
```

- Thực hiện enable chức năng zabbix trong mgr deamon  
```
ceph mgr module enable zabbix
```

- Cấu hình ceph-mgr để lấy thông tin tớ zabbix-server 
```
ceph config-key ls

[
  "mgr/zabbix/identifier",
  "mgr/zabbix/interval",
  "mgr/zabbix/zabbix_host",
  "mgr/zabbix/zabbix_port",
  "mgr/zabbix/zabbix_sender"
]
```

- Trong đó :
  - identifier : khai báo source cho metric, tên này sẽ phải trùng với hostname khai báo trên zabbix server. 
  - interval : thời gian push dữ liệu từ agent lên zabbix-server 
  - zabbix_host : IP hoặc domain name của zabbix server 
  - zabbix_port : mặc định zabbix-sender sử dụng cổng 10050
  - zabbix_sender : đường dẫn chương trình zabbix_sender 

- Cấu hình các thông số cho mode mgr zabbix. Chỉnh sửa IP và hostname theo môi trường 
```
ceph zabbix config-set zabbix_host 192.168.30.194
ceph zabbix config-set identifier ceph1 
ceph zabbix config-show
```


## 2.2. Cấu hình trên các node Openstack Controller




- Cài đặt sshpass
```
yum install sshpass -y 
```

- Khởi tạo project và user cho quá trình giám sát 
```
openstack project create monitor --domain default 
openstack user create monitor --domain default --project monitor --password monitor123
openstack role add --project monitor --user monitor member

```

- Khởi tạo image 
```
wget http://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img
openstack image create "cirros" \
  --file cirros-0.4.0-x86_64-disk.img \
  --disk-format qcow2 --container-format bare \
  --protected  --private --project monitor
```

- Khởi tạo flavor 
```
openstack flavor create --ram 2048 --disk 10 --vcpus 1 --private --project monitor m1.monitor
```

- Update security rule 
```
project=`openstack project list -c Name -c ID  -f value | grep monitor | awk '{print $1}'`
sec_group=`openstack security group list -c ID -c Project -f value | grep $project | awk '{print $1}'`
openstack security group rule create --remote-ip 0.0.0.0/0 --protocol any --ingress $sec_group
```

- List danh sách các network 
```
openstack network list -c ID -f value
```

- Script khởi tạo máy ảo 
```
net=`openstack network list -c ID -f value --os-auth-url http://192.168.100.32:5000/v3 --os-identity-api-version 3 --os-project-name monitor --os-username monitor --os-password monitor123 |  awk 'NR==1' `

openstack server create --image cirros --flavor  m1.monitor --nic net-id=$net zabbix-test-vm \
--os-auth-url http://192.168.100.32:5000/v3 \
--os-identity-api-version 3 \
--os-project-name monitor \
--os-username monitor \
--os-password monitor123

IP_server=`openstack server show zabbix-test-vm  --os-auth-url http://192.168.100.32:5000/v3 --os-identity-api-version 3 --os-project-name monitor --os-username monitor --os-password monitor123 -c addresses -f value | cut -d"=" -f2`

sshpass -p gocubsgo ssh cirros@$IP_server
```




## 3. Cấu hình trên Zabbix Server 

### 3.1. Cấu hình template cho CEPH Monitor 

- Với CEPH sau khi đã cài đặt và khởi động các agent, thực hiện khởi tạo template
- Lên source code tương ứng với các version của CEPH để lấy các template sẵn. Ví dụ trong trường hợp sử dụng version mimic thì sẽ sử dụng đường dẫn sau đây : https://github.com/ceph/ceph/blob/mimic/src/pybind/mgr/zabbix/zabbix_template.xml

- Sau khi đã lấy được nội dung của template và lưu vào máy, thực hiện khởi tạo template từ file xml này bằng việc import tại Configuration -> templates -> import 
![](https://i.imgur.com/wXvUU98.png)



### 3.2.  Cấu hình template cho Openstack 

- Khởi tạo template, và link tới template `Template OS Linux`
![](https://i.imgur.com/HLaEzxg.png)

- Khởi tạo danh sách các marco 
![](https://i.imgur.com/OWlmS3L.png)

- Khởi tạo danh sách các application  liên quan đến openstack
![](https://i.imgur.com/HCpLOBs.png)

- Khởi tạo item liên quan đến check sum memory các dịch vụ 
![https://i.imgur.com/pU6mJH1.png]

- Danh sách các Item load 
![](https://i.imgur.com/BnK3QdK.png)


- Khởi tạo các item liên quan đến get endpoint ( Ví dụ Keystone)
![](https://i.imgur.com/29LH5ay.png)

- Sau khi đã get được Header của request, để tiện lợi cho việc trigger item, thực hiện expressions dữ liệu 
![](https://i.imgur.com/F2JwYhc.png)


- Chỉ sửa trong zabbix server, enable thư mục External check và Timeout  tại `/etc/zabbix/zabbix_server.conf`
```
ExternalScripts=/usr/lib/zabbix/externalscripts
Timeout=30

```

- Sau đó restart lại server zabbix
```
systemctl restart zabbix-server
```

- Khởi tạo script khởi tạo VM kiểm tra workflow tại `/usr/lib/zabbix/externalscripts/createvm`
```

#! /usr/bin/python

from keystoneauth1.identity import v3
from keystoneauth1 import session
from keystoneclient.v3 import client
from glanceclient.v2 import client as glance_client
from novaclient import client as nova_client
from neutronclient.v2_0  import client as neutron_client
from novaclient.exceptions import NotFound
from keystoneauth1.exceptions.http import Unauthorized
import random
import json
import time
import sys
import os

## authencation

auth = v3.Password(auth_url="http://192.168.100.32:5000/v3", username="monitor",
                   password="monitor123", project_name="monitor",
                   user_domain_id="default", project_domain_id="default")
sess = session.Session(auth=auth)
keystone = client.Client(session=sess)
glance = glance_client.Client(session=sess)
nova = nova_client.Client(2, session=sess)
neutron = neutron_client.Client(session=sess)

## get ID image cirros
for image in glance.images.list():
    if image["name"] == "cirros":
        image_cirros_id  = image["id"]
        break

## get ID flavor
for flavor in nova.flavors.list():
    if flavor.to_dict()["name"] == "m1.monitor":
        flavor_monitor_id = flavor.to_dict()["id"]
        break


name = "zabbix_test_vm"
image = image_cirros_id
flavor = flavor_monitor_id

## delete old VM
try:
    while True:
        server = nova.servers.find(name=name)
        server.delete()
except NotFound:
    pass

## get network list
network_list = []
for network_dict in neutron.list_networks()["networks"]:
    network_list.append(network_dict["id"])

## create vm
nova.servers.create(name, image, flavor, meta=None, files=None, reservation_id=True, min_count=None, max_count=None, security_groups=None, userdata=None, key_name=None, availability_zone=None, block_device_mapping=None, block_device_mapping_v2=None,  nics=[{"net-id": random.choice(network_list)}] , scheduler_hints=None, config_drive=None, disk_config=None, admin_pass=None, access_ip_v4=None, access_ip_v6=None, trusted_image_certificates=None, host=None, hypervisor_hostname=None)


## check status vm
while True:
    if len(nova.servers.list(search_opts={'status': 'BUILD'})) == 0:
        break

## get IPADDR VM
for instance in nova.servers.list(search_opts={'status': 'ACTIVE'}):
    for i in instance.to_dict()["addresses"].values():
        vm_addr = i[0]["addr"]
        response = os.system('ping -c4 ' + vm_addr +" >/dev/null")
        if response == 0:
            print("UP")



```


- Cấu hình Triger cho workflow
![](https://i.imgur.com/M4k22vU.png)



### 3.2. Khởi tạo hostgroup và host

- Thực hiện khởi tạo host group cho CEPH và OPS Controller 
![](https://i.imgur.com/jokuh9w.png)


- Khởi tạo host cho node ceph1 ( tương ứng với node mgr )
![](https://i.imgur.com/46z1u6n.png)

- Sau đó thực hiện link đến template ceph-mgr Zabbix module
![](https://i.imgur.com/hP2ahsq.png)

- Sau đó host các node ceph, thay vì chờ interval để kiểm tra tính kết nối thực hiện chủ động gửi data bằng cách 
```
ceph zabbix send
```


- Khởi tạo host OPS Controller và link đên template
![](https://i.imgur.com/R3tx6Ku.png)


### 3.3. Kiểm tra data 


- Kiểm tra data node CEPH mgr 
![](https://i.imgur.com/YNSMpAj.png)

## 3.4. Cấu hình thông báo

- Để cấu hình thông báo, thực hiện truy cập  Administration > Media Type. Cấu hình Gmail SMTP cho Zabbix cấu hình như sau 
![](https://i.imgur.com/d9voOfV.png)

- Sử dụng chức năng test email để confirm cấu hình 
![](https://i.imgur.com/dEhaIUg.png)

- Kiểm tra email 
![](https://i.imgur.com/6YxfGhz.png)

- Thực hiện Attach Media cho tài khoản Admin 
![](https://i.imgur.com/1lnqjni.png)



### 3.5. Cấu hình Action 

- Để thực hiện gửi các cảnh báo, thực hiện cấu hình các Action cho hệ thống 

- Lựa chọn Host group để attach action 
![](https://i.imgur.com/5mdHeMS.png)

- Cấu hình thực hiện gửi Gmail khi có lỗi xuất hiện 
![](https://i.imgur.com/lJjubOL.png)

- Thực hiện gửi thông báo đến Gmail khi sự cố được khắc phục 
![](https://i.imgur.com/jQ0SWlB.png)

- Và đây là kết quả, nó spam VCL
![](https://i.imgur.com/NYdQj8l.png)

END.